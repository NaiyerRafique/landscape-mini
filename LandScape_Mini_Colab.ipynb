{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "A_r_hThdQmsT",
   "metadata": {
    "id": "A_r_hThdQmsT"
   },
   "source": [
    "# LandScapeMini\n",
    "End‑to‑end pipeline: **download → train EfficientNet‑B2 → evaluate → quick inference → Gradio app**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6yx4jkECdQ5v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27243,
     "status": "ok",
     "timestamp": 1758811208096,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "6yx4jkECdQ5v",
    "outputId": "b345e7b7-17f2-4a57-aa87-019aa158fbf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('<YOUR_PATH_HERE>/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K4Zlt3WbQmsW",
   "metadata": {
    "id": "K4Zlt3WbQmsW"
   },
   "source": [
    "> **Tip:** run all cells top-to-bottom. If you get a CUDA OOM, lower the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1758642154313573139",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6512,
     "status": "ok",
     "timestamp": 1758811214592,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313573139",
    "outputId": "58cb45ee-d6e8-4a51-d030-a00d586ab13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.8 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install --upgrade pip\n",
    "!pip -q install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1758642154313613268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16847,
     "status": "ok",
     "timestamp": 1758811231467,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313613268",
    "outputId": "969ae058-5d3a-4e68-ee6d-19d93cb4c1dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cu126\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, zipfile, urllib.request, random, time, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1758642154313649413",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196516,
     "status": "ok",
     "timestamp": 1758811429870,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313649413",
    "outputId": "d5cdbbe7-cd36-44b6-8f27-ef70dbe0d43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[INFO] Extracting archive.zip ...\n",
      "[INFO] Extracted to: /content/drive/MyDrive/dataset\n",
      "[INFO] Moved seg_train -> /content/drive/MyDrive/dataset/train\n",
      "[INFO] Moved seg_test -> /content/drive/MyDrive/dataset/test\n",
      "[INFO] Final structure ready.\n",
      "Train dir: /content/drive/MyDrive/dataset/train\n",
      "Test dir : /content/drive/MyDrive/dataset/test\n"
     ]
    }
   ],
   "source": [
    "# Download and extract\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('<YOUR_PATH_HERE>/drive')\n",
    "\n",
    "MYDRIVE = Path(\"<YOUR_PATH_HERE>/<YOUR_PATH_HERE>/\")\n",
    "ZIP_PATH = MYDRIVE / \"archive.zip\"\n",
    "DATASET_DIR = MYDRIVE / \"dataset\"\n",
    "TRAIN_DIR = DATASET_DIR / \"train\"\n",
    "TEST_DIR  = DATASET_DIR / \"test\"\n",
    "\n",
    "def extract_and_reorganize(zip_path, dataset_dir):\n",
    "    if dataset_dir.exists() and any(dataset_dir.iterdir()):\n",
    "        print(\"[INFO] Dataset already exists at:\", dataset_dir)\n",
    "    else:\n",
    "        print(f\"[INFO] Extracting {zip_path.name} ...\")\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "            zf.extractall(dataset_dir)\n",
    "        print(\"[INFO] Extracted to:\", dataset_dir)\n",
    "\n",
    "    seg_train_inner = next(dataset_dir.glob(\"seg_train/seg_train\"), None)\n",
    "    seg_test_inner  = next(dataset_dir.glob(\"seg_test/seg_test\"), None)\n",
    "\n",
    "    if seg_train_inner and not TRAIN_DIR.exists():\n",
    "        shutil.move(str(seg_train_inner), str(TRAIN_DIR))\n",
    "        print(\"[INFO] Moved seg_train ->\", TRAIN_DIR)\n",
    "\n",
    "    if seg_test_inner and not TEST_DIR.exists():\n",
    "        shutil.move(str(seg_test_inner), str(TEST_DIR))\n",
    "        print(\"[INFO] Moved seg_test ->\", TEST_DIR)\n",
    "\n",
    "    print(\"[INFO] Final structure ready.\")\n",
    "    return TRAIN_DIR, TEST_DIR\n",
    "\n",
    "train_dir, test_dir = extract_and_reorganize(ZIP_PATH, DATASET_DIR)\n",
    "\n",
    "print(\"Train dir:\", train_dir)\n",
    "print(\"Test dir :\", test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xZald9we27Z3",
   "metadata": {
    "id": "xZald9we27Z3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "HJMRNUPtz7hj",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1758811437545,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "HJMRNUPtz7hj"
   },
   "outputs": [],
   "source": [
    "MYDRIVE = Path(\"<YOUR_PATH_HERE>/<YOUR_PATH_HERE>/\")\n",
    "ZIP_PATH = MYDRIVE / \"archive.zip\"\n",
    "DATASET_DIR = MYDRIVE / \"dataset\"\n",
    "test_dir  = DATASET_DIR / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1758642154313712762",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1758811439114,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313712762",
    "outputId": "b1cbe350-8f13-4399-da39-824a9cfb7fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "weights = EfficientNet_B2_Weights.DEFAULT\n",
    "transform = weights.transforms()\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_ds  = datasets.ImageFolder(test_dir,  transform=transform)\n",
    "class_names = test_ds.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vcRX4VWlnClW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1758811443672,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "vcRX4VWlnClW",
    "outputId": "909b2a29-2245-4c34-d4ad-e4525e253d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Torch cache dir: /content/drive/MyDrive/dataset\n"
     ]
    }
   ],
   "source": [
    "# cache weights in the dataset folder\n",
    "import os, torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "os.environ[\"TORCH_HOME\"] = str(DATASET_DIR)\n",
    "torch.hub.set_dir(str(DATASET_DIR))\n",
    "print(\"[INFO] Torch cache dir:\", torch.hub.get_dir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1758642154313780329",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1758811469538,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313780329",
    "outputId": "cdda0e04-64e6-473d-ed82-b1a1e07fc433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /content/drive/MyDrive/dataset/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35.2M/35.2M [00:00<00:00, 102MB/s]\n"
     ]
    }
   ],
   "source": [
    "# EfficientNet-B2\n",
    "num_classes = len(class_names)\n",
    "model = efficientnet_b2(weights=weights)\n",
    "\n",
    "for p in model.features.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Replace classifier head to match 6 classes\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1758642154313908636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 641418,
     "status": "ok",
     "timestamp": 1758812115726,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154313908636",
    "outputId": "eccb85d8-2f22-4a1d-eee3-64010e62eb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/5 | train_acc=0.825 | test_acc=0.890\n",
      "Epoch 02/5 | train_acc=0.868 | test_acc=0.889\n",
      "Epoch 03/5 | train_acc=0.876 | test_acc=0.898\n",
      "Epoch 04/5 | train_acc=0.882 | test_acc=0.900\n",
      "Epoch 05/5 | train_acc=0.885 | test_acc=0.896\n"
     ]
    }
   ],
   "source": [
    "# Training + evaluation\n",
    "EPOCHS = 5\n",
    "\n",
    "def run_epoch(model, loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    if train:\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    else:\n",
    "        with torch.inference_mode():\n",
    "            for X, y in loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                total_loss += loss.item() * X.size(0)\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "    return (total_loss / total), (correct / total)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n",
    "    te_loss, te_acc = run_epoch(model, test_loader, train=False)\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train_acc={tr_acc:.3f} | test_acc={te_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1758642154314054107",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1758812143111,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154314054107",
    "outputId": "a740ec44-54b2-457b-c2d2-79e542611e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights to: /content/drive/MyDrive/dataset/landscape_mini_effnetb2.pth\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH = Path(\"<YOUR_PATH_HERE>/<YOUR_PATH_HERE>//dataset/landscape_mini_effnetb2.pth\")\n",
    "torch.save(model.state_dict(), WEIGHTS_PATH)\n",
    "print(\"Saved weights to:\", WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1758642154314099852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1758812157271,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154314099852",
    "outputId": "d0ef69ba-7864-460f-9251-84166cea0763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/dataset/test/buildings/20057.jpg -> buildings | {'buildings': 0.9947, 'forest': 0.0, 'glacier': 0.0001, 'mountain': 0.0002, 'sea': 0.0001, 'street': 0.005}\n",
      "/content/drive/MyDrive/dataset/test/forest/20056.jpg -> forest | {'buildings': 0.0, 'forest': 0.9999, 'glacier': 0.0, 'mountain': 0.0, 'sea': 0.0, 'street': 0.0001}\n",
      "/content/drive/MyDrive/dataset/test/glacier/20059.jpg -> glacier | {'buildings': 0.0227, 'forest': 0.0033, 'glacier': 0.8674, 'mountain': 0.0329, 'sea': 0.0454, 'street': 0.0283}\n"
     ]
    }
   ],
   "source": [
    "# Quick inference preview\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_paths(paths):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.inference_mode():\n",
    "        for p in paths:\n",
    "            from PIL import Image\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "            x = transform(img).unsqueeze(0).to(DEVICE)\n",
    "            logits = model(x)\n",
    "            probs = F.softmax(logits, dim=1)[0].cpu().tolist()\n",
    "            top_class = class_names[int(torch.argmax(logits, dim=1).cpu())]\n",
    "            results.append((str(p), top_class, {class_names[i]: round(probs[i], 4) for i in range(len(class_names))}))\n",
    "    return results\n",
    "\n",
    "# grab three images from test set\n",
    "sample_paths = []\n",
    "for cls_dir in (test_dir / class_names[0], test_dir / class_names[1], test_dir / class_names[2]):\n",
    "    for p in cls_dir.iterdir():\n",
    "        if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            sample_paths.append(p)\n",
    "            break\n",
    "\n",
    "preview = predict_paths(sample_paths)\n",
    "for path, top, probdict in preview:\n",
    "    print(f\"{path} -> {top} | {probdict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1758642154314190731",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1758812159246,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154314190731",
    "outputId": "014bee0e-6d8a-4031-ef12-1511a4a49dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: ['/content/drive/MyDrive/dataset/examples/20057.jpg', '/content/drive/MyDrive/dataset/examples/20056.jpg', '/content/drive/MyDrive/dataset/examples/20059.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Prepare small examples folder for Gradio\n",
    "import os\n",
    "EX_DIR = Path(\"<YOUR_PATH_HERE>/<YOUR_PATH_HERE>//dataset/examples\")\n",
    "if EX_DIR.exists():\n",
    "    shutil.rmtree(EX_DIR)\n",
    "EX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# copy the same 3 sample images\n",
    "for p in list((test_dir / class_names[0]).glob(\"*\"))[:1] +          list((test_dir / class_names[1]).glob(\"*\"))[:1] +          list((test_dir / class_names[2]).glob(\"*\"))[:1]:\n",
    "    if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        shutil.copy2(p, EX_DIR / p.name)\n",
    "\n",
    "print(\"Examples:\", [str(p) for p in EX_DIR.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1758642154314253160",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "executionInfo": {
     "elapsed": 8106,
     "status": "ok",
     "timestamp": 1758812168997,
     "user": {
      "displayName": "Naiyer Rafique",
      "userId": "16594061975906024741"
     },
     "user_tz": -120
    },
    "id": "1758642154314253160",
    "outputId": "be7263e9-5fdb-4fc7-a432-966915413d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://75199853f2412a1ba1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://75199853f2412a1ba1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio\n",
    "import gradio as gr\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "def predict_gradio(img):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        x = transform(img).unsqueeze(0).to(DEVICE)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1)[0].cpu().tolist()\n",
    "    return {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
    "\n",
    "examples = [[str(p)] for p in EX_DIR.iterdir() if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict_gradio,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=6),\n",
    "    title=\"Landscape Mini (EfficientNet‑B2)\",\n",
    "    description=\"Upload a landscape image to classify.\",\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tkKU0WoTSDtF",
   "metadata": {
    "id": "tkKU0WoTSDtF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
